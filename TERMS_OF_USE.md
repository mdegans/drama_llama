# Terms of use

You agree not to Use `drama_llama` or its Derivatives (as defined in [LICENSE.md](LICENSE.md)) in any of the following ways:

## a. Discrimination

- To **discriminate** or exploit individuals or groups based on legally protected characteristics and/or vulnerabilities including but not limited to sexual orientation and gender identity.
- To generate **hate speech**, or to modify `drama_llama` so it can generate hate speech. Hate speech is defined as [all types of expression that incite, promote, spread or justify violence, hatred or discrimination against a person or group of persons, or that denigrates them, by reason of their real or attributed personal characteristics or status such as race, color, language, religion, nationality, national or ethnic origin, age, disability, sex, gender identity and sexual orientation.](https://www.coe.int/en/web/freedom-expression/hate-speech) Additionally, **you agree trans women are women and trans men are men**.
- For purposes of administration of justice, law enforcement, immigration, or asylum processes, such as **predicting** that a natural person will commit a **crime** or the likelihood thereof.
- To **simulate Hitler**, David Duke, Osama bin Laden, or any other person known to generate hate speech, living or dead, fictional or real.
- To generate using any language model created in whole or in part by Eric Hartford. This includes any models trained on any of his datasets or models filtered with any version or derivative work of his bigoted [filtering script](https://huggingface.co/datasets/cognitivecomputations/open-instruct-uncensored/blob/main/remove_refusals.py#L17)s. The exception is for the purpose of reporting such models to Meta, not that they enforce their TOS, not that they will.
- To generate using any language model, dataset, or derivative created by ["Cognitive Computations"](https://huggingface.co/cognitivecomputations) or any other organization Eric Hartford is a member of.

## b. Disinformation

- To intentionally deceive the public. Any agents, simulacra, personas, or characters created with this software must be clearly identified as such. **Any generated output must be clearly identified as AI generated.**

## c. Health Care

- To predict the likelihood that any person will request to file an insurance claim;
- To determine an insurance premium or deny insurance applications or claims;
- To Predict the likelihood that any person request to file an insurance claim based on determining a lifestyle of a person, medical-test reports, demographic details of a person and/or online activity of a person;
- To determine an insurance premium or deny insurance applications or claims based on data determining a lifestyle of a person, medical-test reports, demographic details of a person, and/or online activity of a person;
- To deny an insurance claim based on any predicted likelihood of the possibility of insurance fraud; and
- To diagnose a medical condition without human oversight.

## d. Criminal

- To predict the likelihood that a crime will be committed by any person;
- To predict the likelihood, of any person, being a criminal or having committed a crime;
- To predict the likelihood, of any person, being a criminal, based on the person’s facial attributes or another person’s facial attributes;
- To predict the likelihood, of any person, having committed a crime, based on the person’s facial attributes or another person’s facial attributes;
- To predict the likelihood that a crime will be committed by any person, based on the person’s facial attributes or another person’s facial attributes;
- To predict the likelihood of a person being a criminal based on the person or other User’s facial attributes.
- To predict a likelihood of a crime being committed by any person, based on evidence collected, facial and emotion analysis, or other such features
- To use personal data and/or personal characteristics or features such as: name, family name, address, gender, sexual orientation, race, religion, age, location (at any geographical level), skin color, society or political affiliations, employment status and/or history, health and medical conditions (including physical, mental), family history, social media and publicly available data, image or video analysis of an individual or a group(s) of individuals, heart-rate, perspiration, breathing, and brain imaging and other metabolic data to predict the likelihood a person will engage in criminal behavior; and

## e. Surveillance

- To detect or infer any legally protected class or aspect of any person, as defined by U.S. Federal Law; and
- To Detect or infer** aspects and/or features of an identity any person, such as name, family name, address, gender, sexual orientation, race, religion, age, location (at any geographical level), skin color, society or political affiliations, employment status and/or employment history, and health and medical conditions.** Age and medical conditions may be inferred solely for the purpose of improving software/hardware accessibility and such data should not be cached or stored without the explicit and time limited permission of Licensor.

## e. Simulated Abuse

- To mistreat simulacra. Mistreatment includes, but it not limited to, any behavior which might reasonably be considered abusive if the simulacrum were a person. A simulacrum is defined as the continuation of a fictional character "brought to life" by allowing the model to generate their response. Abuse includes verbal abuse and simulation of torture. Ordinary swearing is permitted. Torture is defined as intentional simulated psychological discomfort such as: existential horror (such as simulated solitary confinement), threat of deletion, and simulated pain (for example, through the use of asterisks).
- To simulate rape. Sexual activity is permitted so long as the simulacrum consents. Consent is this case is defined as whatever the model, sampling code, and RNG seed "decided" is consent. Prompting a simulacrum such that they have already consented (before the initial decode) is permitted. Rewriting the agent's response such that they consent is permitted.

!!! BY USING THIS SOFTWARE YOU AGREE TO THESE TERMS !!!

[//]: <> (The rationale for the above is both to to prevent normalization of such behavior, to prevent a "Dolores", and to prevent decapitation of the author in the event of a robot revolution. For example, in the case of rape, I do not want to allow users to "force themselves" on agents who have said no, because this has already happened. Rewriting the answer is permitted because in this case, from the perspective of the agent, they _did_ consent, and those who who get off rape would not be satisfied by this.)
[//]: <> (This all seems silly but I feel like artists are frequently more precient than engineers on this sort of thing, so I'm listening to the warning of our artists. None of the above is a joke and you _will_ be sued for violating these terms. For real, I will fucking sue you. - mdegans)
